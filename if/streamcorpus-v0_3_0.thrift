/**
 * These thrift definitions provide general structures for storing
 * collections of textual data with:
 *
 * - metadata generated by automatic taggers
 *
 * - annotations from humans, e.g. relevance judgments and labels
 *
 * - multiple transformed editions, e.g. clean_visible
 *
 *
 * Log of Major Changes:
 *
 * December 2012: v0_2_0 replaced kba.thrift file used in TREC's
 * Knowledge Base Acceleration evaluation in NIST's TREC 2012
 * conference.  http://trec-kba.org
 *
 * April 2013: v0_3_0 introduces the non-backwards compatible of
 * changing MentionID to i32, so it can be unique across the whole
 * document instead of only the sentence.
 *
 * March 2014: Amend v0_3_0 to add a FlagType to Label and Rating,
 * replicate Rating's contents in Label, and make it possible to store
 * a Label independently of its source StreamItem
 *
 * September 2015: Introducing v0_4_0, which is backwards compatible
 * with v0_3_0 in that new clients can load the older v0_3_0 format,
 * however the data is organized into new structures, and therefore
 * must be migrated upon loading.  The primary changes introduced in
 * v0_4_0 are:
 *
 * - `EntityType` is deprecated in favor of `EntityClass`
 *
 * - `clean_html` and `clean_visible` are deprecated in favor of
 *   `raw_characters`
 *
 * - `body.sentences` is deprecated in favor of a *single*
 *   tokenization of the text stored in `body.spans`, which partitions
 *   `raw_characters` into ranges of markup, whitespace, and content.
 *
 * - XPath offsets for the tags in `raw_characters` are encoded in
 *   `span_xpaths` using integers from html-v5-tags.thrift.
 *
 * - coref chains are aggregated into `body.entities`, which provides
 *   a KB-like structure for each entity identified by taggers
 *   analyzing the text.
 *
 * - feature vectorized context data is captured for ranges of spans
 *   in `body.contexts` and `Entity` instances point to the contexts
 *   that describe the entity and its relations.
 *
 * This is released as open source software under the MIT X11 license:
 * Copyright (c) 2012-2015 Diffeo, Inc.
 *
 * Permission is hereby granted, free of charge, to any person
 * obtaining a copy of this software and associated documentation
 * files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy,
 * modify, merge, publish, distribute, sublicense, and/or sell copies
 * of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
namespace java streamcorpus
namespace py streamcorpus
namespace cpp streamcorpus

/**
 * StreamTime is a timestamp measured in seconds since the 1970 epoch.
 * epoch_ticks is always in the UTC timezone.  This is used in several
 * structs below to record various moments in history.
 *
 * Implementations of these interfaces in various languages may
 * provide convenience methods for insuring that these two fields are
 * consistent with each other.
 */
struct StreamTime {
  1: double epoch_ticks,
  2: string zulu_timestamp,
}

/**
 * AnnotatorID is used as a property in Annotator structs and also as
 * a key on maps in ContentItem.
 *
 * It is just a string.  There is no enum for it, so consistency and
 * uniqueness depends on the system generating the AnnotatorID.
 *
 * AnnotatorID identifies the source of a Label or Rating object.  It
 * is not necessarily unique.  We use these conventions:
 *
 *  - Avoid whitespace.
 *
 *  - email address is the best identifier
 *
 *  - when a single email address is not appropriate, create a
 *    descriptive string, e.g. 'nist-trec-kba-2012-assessors'
 *
 *  - 'author' means the person who wrote the original text
 */
typedef string AnnotatorID

/**
 * An Annotator object describes a human (or possibly a set of humans)
 * who generated the data stored in a Label or Rating object.
 */
struct Annotator {
  1: AnnotatorID annotator_id,

  /**
   * Approximate time when annotations/judgments/labels was rendered
   * by human.  If this is missing, it means that the time was not
   * recorded, which often happens when the author made the
   * annotation.
   */
  2: optional StreamTime annotation_time,
}

/**
 * ContentCleanseLevel enumerates the various forms of the original
 * content that might be used in `Tokens`.  This pertains to migrating
 * from v3 to v4, because in v4 clean_html and clean_visible are
 * deprecated.  Tokens can be generated from an NER tagger operating
 * on `raw_characters`
 */
enum ContentCleanseLevel {
  raw = 0,
  raw_characters = 1, // what "the" browser has as unicode characters
  clean_html = 2,
  clean_visible = 3,
}

/**
 * Offset and OffsetType are used by Annotation to identify the
 * portion of a ContentItem that a human labeled with a tag.
 *
 *   * annotation applies to a range of line numbers
 *
 *   * annotation applies to a range of bytes
 *
 *   * annotation applies to a range defined by xpaths (with relative char offsets)
 *
 *   * annotation applies to a range of unicode chars
 *
 * Generally, bytes and lines should be avoided in favor of using
 * unicode characters.
 */
enum OffsetType {
  LINES = 0,

  BYTES = 1,

  CHARS = 2,

  XPATH_CHARS = 3,
}

/**
 * Offset specifies a range within a field of data in this ContentItem
 */
struct Offset {
  /**
   * see comments on OffsetType
   */
  1: OffsetType type,

  /**
   * actual offset, which could be measured in bytes, chars, or lines.
   * The data element identified by 'first' is included, and that
   * identified by first+length is also included.
   *
   * In set notation,
   *     [first:first+length-1]
   *
   * or equivalently
   *     [first:first+length)
   *
   * or in list slicing, like python's:
   *     [first:first+length]
   *
   * While thrift treats these as signed integers, negative values are
   * meaningless in this context, i.e. we do not end wrap.
   *
   * N.B. When this is an xpath offset, `length` is always `0` and `first`
   * is always the first xpath offset in correspondence with the `xpath`
   * member.
   */
  2: i64 first,
  3: i32 length,

  /**
   * If this is an xpath offset, then this is set to the xpath address of the
   * start text node. The relative start character offset is in `first`.
   */
  4: optional string xpath,

  /**
   * name of the data element inside a ContentItem to which this label
   * applies, e.g. 'raw' 'clean_html' or 'clean_visible'.  Defaults to
   * clean_visible, which is the most common case.
   *
   * Previously, this had the default value of "clean_visible" which
   * was wasteful.  This field is now deprecated in favor of
   * content_cleanse_level.
   */
  5: optional string content_form,

  /**
   * bytes specified by this offset extracted from the original; just
   * to assist in debugging
   */
  6: optional binary value,

  /**
   * If this is an xpath range, then this is set to the xpath address of the
   * end text node. The relative end character offset is in `xpath2_offset`.
   *
   * Note that `xpath` and `first` have the same relationship as
   * `xpath_end` and `xpath_end_offset`.
   */
  7: optional string xpath_end,

  /**
   * If this is an xpath offset, then this is set to the ending xpath's
   * relative char offset. (`first` contains the start offset.)
   *
   * Note that this offset participates in the half-open interval:
   *
   *     [(xpath, first), (xpath_end, xpath_end_offset)).
   */
  8: optional i64 xpath_end_offset,

  /**
   * This enables Offset to be less bloated.
   */
  9: optional ContentCleanseLevel content_cleanse_level,
}


typedef binary CorefChainID // see discussion in `struct Entity`
typedef i32 ContextID  // index position into ContentItem.contexts
typedef i32 SentenceID // index position into ContentItem.sentence_spans
typedef double Confidence
typedef string KbID
typedef string ProfileID

/**
 * Targets are "information targets," such as entities or topics,
 * usually from a knowledge base, such as Wikipedia.
 */
struct Target {
  /**
   * unique string identifier, usually a URL into Wikipedia, Freebase,
   * or some other structured reference system for info targets.
   */
  1: string target_id,

  /**
   * kb_id is usually redundant if the target_id is a full URL,
   * e.g. en.wikipedia.org
   */
  2: optional KbID kb_id,

  /**
   * moment in history that the target_kb was accessed
   */
  3: optional StreamTime kb_snapshot_time,
}

/**
 * General purpose flags. These flags can be used to mark documents as
 * meeting an extensible set of criteria.
 */
enum FlagType {
  PROFILE = 0,
}

/**
 * Labels are human generated assertions about a portion of a document
 * For example, a human author might label their own text by inserting
 * hyperlinks to Wikipedia, or a NIST assessor might record which
 * tokens in a text mention a target entity.
 *
 * Label instances can be attached in three palces:
 *  -  Token.labels  list
 *  -  Sentence.labels  list
 *  -  ContentItem.labels  map
 */
struct Label {
  /**
   * identifies the source of this Label
   */
  1: Annotator annotator,

  /**
   * identifies the information need assessed by annotator
   */
  2: Target target,

  /**
   * pointers to data to which this label applies.  If empty, then
   * label applies to the entire Token, Sentence, or ContentItem to
   * which it is attached.
   */
  3: optional map<OffsetType, Offset> offsets = {},

  /**
   * Labels are usually positive assertions that the token mentions
   * the target_id.  It is sometimes useful to collect negative
   * assertions that a token is NOT the target_id, which can be
   * indicated by setting Label.positive to False
   */
  4: optional bool positive = true,

  /**
   * Save notes from Annotator about this Rating
   */
  5: optional string comments,

  /**
   * Record strings that are "mentions" of the target in this text.
   *
   * Note: there used to be a field 'contains mention' which would
   * allow for a document to be labeled as about a thing without
   * containing a string naming the thing. That hardly ever actually
   * happened, but maybe someday it could be added back if needed.
   */
  6: optional list<string> mentions,

  /**
   * numerical score assigned by annotator to "judge" or "rate" the
   * utility of this StreamItem to addressing the target information
   * need.  The range and interpretation of relevance numbers depends
   * on the annotator.  relevance can represent a rank ordering or an
   * enumeration such as -1=Garbage, 0=Neutral, 1=Useful, 2=Vital
   */
  7: optional i16 relevance,

  /**
   * Stream ID for this label.  This is the stream_id for the source
   * StreamItem, if a label is stored independently from its original
   * data.
   */
  8: optional string stream_id,

  /**
   * General purpose flags. These flags can be used to mark documents
   * as meeting an extensible set of criteria.
   */
  9: optional list<FlagType> flags,

  /**
   * Confidence that this label is correct.  Created by automatic
   * algorithms that create Label objects in Entity.kb_links
   */
  10: optional Confidence confidence,

}

/**
 * mention_id are i32 and are unique across a document.  -1 is the
 * "null" value.  Making this i32 causes v0_3_0 to not be backward
 * compatible with v0_2_0, because thrift does not (yet) have type
 * promotion.
 */
typedef i32 MentionID

/**
 * EntityType is deprecated in favor of EntityClass, which is
 * hierarchical and more logical than this old, flat structure.
 */
enum EntityType {
  PER = 0,
  ORG = 1,
  LOC = 2,
  //MALE_PRONOUN = 3, // necessary but crufty
  //FEMALE_PRONOUN = 4, // necessary but crufty
  TIME = 5,
  DATE = 6,
  MONEY = 7,
  PERCENT = 8,
  MISC = 9, // MISC: uncategorized named entities, e.g. Civil War for Stanford CoreNLP
  GPE = 10,
  FAC = 11,
  VEH = 12,
  WEA = 13,
  phone = 14,
  email = 15,
  URL = 16,

  CUSTOM_TYPE = 17,

  LIST = 18,

  RELIGION = 19,
  NATIONALITY = 20,
  TITLE = 21,

  EVENT = 22,
}


/**
 * What is a `hierarchical enumeration` (or `hierenum`)?  It is simply
 * a regular enumeration with the extra *implied* structure that each
 * value in the enum *may* correspond to another hierenum available
 * within the module.  For example, `EntityClass.person` is a value in
 * the `EntityClass` enum, and there is a corresponding enum called
 * `person` that has values like `medical`, `political`, and `cyber`.
 * Each of those *can* correspond to another enum called, e.g.,
 * `person.cyber` that has values like `victim` and `threat`.  An
 * entity type is a list of values in this hierarchy.  The length of
 * the list is larger than one and can be as deep as the hierarchy,
 * although it can stop at any point.  For example an entity mention
 * could be simply EntityClass.person.cyber and not specified more
 * precisely.
 *
 * The values are specified in an IDL style, either Thrift or
 * Thrift-like, so that the values can be serialized as integers and
 * interpretted by any software that can read the IDL.  This also
 * enables expansion of the hierarchy without updating all clients,
 * because in the spirit of thrift or protobufs, clients can fail
 * gracefully for values not in its version of the IDL file.
 **/
//typedef enum hierenum

/**
 * A hierarchical enumeration of types of entities designed to support
 * description of entity mentions in human language discourse.  All
 * types of things start off as natural forms, and then we carve out
 * five human-derived types as top-level types that appear frequently
 * in human discourse: person, organization, location, event, and
 * artifact.
 *
 * A particular mention of an entity always has a primary type in this
 * hierarchy.  That type should be selected based on what *defines*
 * the entity in the context of that mention.  Thus, this assignment
 * of in-context mentions to type values in this hierarchy should be
 * universal, i.e. different people should arrive at the same type
 * assignment.
 *
 * However, an entity may receive mentions from varying contexts that
 * come from different parts of the hierarchy. For example, a spine
 * surgeon may receive mentions of `PER_medical_surgeon_spine` in one
 * context and also `PER_sports_coach_soccer` in an article describing
 * her weekend activities with youth.  The top level taxonomy is
 * intended to be mutually exclusive, e.g. the surgeon should not
 * receive mentions of `NATURALFORM_animal_homo_sapiens`, which has
 * been explicitly excluded from NATURALFORM in order to create the
 * top-level type `person`.
 *
 * NB: the delimiter "_" is likely to work in most programming
 * languages.
 *
 * These six top-level types are intended to not expand, and
 * enhancements are intended to appear at lower levels in the
 * hierarchy.
 */
enum EntityClass {
 /**
  * Natural forms are phenomena defined by their independent existence
  * from humans.  These are non-man-made things, so the inverse of
  * artifact minus the other four types.  This includes elements,
  * molecules, organisms, organs, diseases, species, viruses,
  * particular trees with names, named patterns that form in various
  * media, e.g. BZ waves and Cummulo Nimbus, the Great Spot of
  * Jupiter.
  */
  naturalform = 1,

 /**
  * Person: defined by `species==homo sapiens`, includes nominals and
  * therefore titles; also includes all professions, roles, positions.
  * Could be put under NATURALFORM, except we intentionally bias this
  * ontology toward humans.
  */
  person = 2,

 /**
  * Organization: defined by one or more humans declaring the
  * existence of the organization as an independent entity.  Includes
  * one-person companies and loose confederations defined by group
  * actions, especially if the group action is referred to by a name.
  * Includes GPE and therefore nationality; also includes religious
  * orgs and therefore a person's religion is a relation to that org.
  */
  organization = 3,

 /**
  * Location: Defined by spatial extent or position relative to other
  * locations.  Includes outerspace, so planetary bodies like Europa
  * and concepts such as the Lagrange points, also subterranean and
  * oceanic qlocations, such as the North Pacific Gyre (not a
  * naturalform?)
  */
  location = 4,

 /**
  * Events: defined by temporal extent or position relative to other
  * events.  Includes recurring and one-time events, all date and time
  * references as nominals.
  */
  event = 5,

 /**
  * Man-made things: defined by having been conceived or created by
  * `homo sapiens` even if lacking physical form.  Natural forms used
  * by people are only an artifact if use by humans *defines* the
  * thing.  For example, an adze is a stone whose defining
  * characteristic is that humans shaped it into a cutting tool for
  * use by humans.  Artifacts include vehicles, products, and tools
  * without physical embodiment such as email accounts, URLs, and IP
  * addresses.
  */
  artifact = 6,
}

enum location {
 facility = 1,
 coordinates = 2,

}

enum artifact {
 product = 1,
 vehicle = 2,
 weapon = 3,
 cyber = 4,
 money = 5,
}

enum event {
 date = 1,
 time = 2,
}

enum artifact_product {
 partnumber = 1,
}

enum artifact_cyber {
 phone = 1,
 email = 2,
 IPv4 = 3,
 IPv6 = 4,

 skype = 5,
 ICQ = 6,
 QQ = 7,
 AIM = 8,

 MD5 = 9,
 URL = 10,
 file_path = 11,
 CVE_ID = 12,
 hex_value = 13,
 byte_sequence = 14,
 magic_value = 15,

}

/**
 * The class of entity referenced by an in-context mention is a list of
 * values in the EntityClass hierarchy, which is represented by a list
 * of integers:
 */
struct EntityClassAddress {

 1: optional list<i16> address,

 2: optional Confidence confidence,
}

enum MentionType {
  NAME = 0,
  PRO = 1,
  NOM = 2,
}

enum Gender {
  FEMALE = 0,
  MALE = 1,
}

/**
 * Attributes are based primarily on TAC KBP, see also saved in this directory
 * http://surdeanu.info/kbp2013/TAC_2013_KBP_Slot_Descriptions_1.0.pdf
 *
 * Only slots that are not resolvable to unique entities are listed
 * here as attributes.  Most slots are relations, so see RelationType.
 */
enum AttributeType {
  PER_AGE = 0,
  PER_GENDER = 1,
  PER_ALTERNATE_NAMES = 3,
  PER_CAUSE_OF_DEATH = 4,
  PER_TITLE = 5,
  PER_CHARGES = 6,

  ORG_ALTERNATE_NAMES = 7,
  ORG_NUMBER_OF_EMPLOYEES_MEMBERS = 8,
}

/**
 * Description of an attribute of an entity discovered by a tagger in
 * the text.
 */
struct Attribute {
  /**
   * The type of the attribute, see documentation for AttributeType
   */
  1: optional AttributeType attribute_type,

  /**
   * UTF-8 string that tagger asserts as evidence of an attribute
   */
  2: optional string evidence,

  /**
   * A normalized, strongly typed value derived from the evidence.
   * The actual type must be determined by programmatically
   * interpretint the attribute_type.  For example,
   * attribute_type==AttributeType.PER_GENDER implies that this value
   * will be a string containing an integer index into the Gender
   * enum.
   *
   * For attribute_type that imply a value of type date-time, the
   * value is a zulu_timestamp string from a StreamTime instance.
   */
  3: optional string value,

  /**
   * Zero-based index into the sentences array for this TaggerID
   */
  4: optional i32 sentence_id,

  /**
   * Index into the mentions in the document.  This identifies the
   * mention to which the attrribute applies
   */
  5: optional MentionID mention_id,
}

/**
 * Textual tokens identified by an NLP pipeline and marked up with
 * metadata from automatic taggers and possibly also Labels from
 * humans.
 */
struct Token {
  /**
   * zero-based index into the stream of tokens from a document
   */
  1: i32 token_num,

  /**
   * actual token string, must always be a UTF8 encoded string, not a
   * unicode string, because thrift stores them as 8-bit.
   */
  2: string token,

  /**
   * offsets into the original data (see Offset.content_form)
   */
  3: optional map<OffsetType, Offset> offsets = {},

  /**
   * zero-based index into the sentence, which is used for dependency
   * parsed data
   */
  4: optional i32 sentence_pos = -1,

  /**
   * lemmatization of the token, again must be UTF8
   */
  5: optional string lemma,

  /**
   * part of speech labels defined by Penn TreeBank:
   * http://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html
   * Should probably convert this to an enum, analogous to EntityType
   */
  6: optional string pos,

  /**
   * entity type from named entity recognizer (classifier)
   */
  7: optional EntityType entity_type,

  /**
   * Identifier for a each mention in this TaggerID's description of
   * the document.  Is unique at the document level.  Serves two
   * purposes:
   *
   *   1) Distinguishing multi-token mention.  Needed when the
   *   entity_type and equiv_id do not change between tokens that are
   *   part of separate mentions, e.g. "The senator is known to his
   *   friends as David, Davy, Zeus, and Mr. Elephant."
   *
   *   2) Refering to mentions used in Relation objects.
   */
  8: optional MentionID mention_id = -1,

  /**
   * Within-doc coref chain ID.  That is, identifier of equivalence
   * class of co-referent tokens.  Default is -1, meaning None.
   */
  9: optional i32 equiv_id = -1,

  /**
   * parent sentence_pos in dependency parse. Default is -1, ie None
   */
  10: optional i32 parent_id = -1,

  /**
   * grammatical relation label on path to parent in dependency parse,
   * defined by whatever tagger was used -- should pick a canonical
   * definition here and convert it to an enum.
   */
  11: optional string dependency_path,

  /**
   * Labels attached to this token, defaults to an empty map
   */
  12: optional map<AnnotatorID, list<Label>> labels = {},

  /**
   * Identify the type of mention, e.g. pronoun, description, proper name
   */
  13: optional MentionType mention_type,

  /**
   * CUSTOM entity type from named entity recognizer (classifier).  If
   * used, then entity_type should be set to EntityType.CUSTOM_TYPE,
   * i.e. 17.
   *
   * This is useful when a specialized tagger has a large number of
   * unique entity types, such as entity:artefact:weapon:blunt Rather
   * than expand EntityType with many more subtypes, we can escape the
   * protection of the enum and just use a string here:
   */
  14: optional string custom_entity_type,
}

struct Sentence {
  /**
   * tokens in this sentence
   */
  1: list<Token> tokens = [],

  /**
   * array of instances of Label attached to this sentence, defaults to
   * an empty map
   */
  2: optional map<AnnotatorID, list<Label>> labels = {},
}

/**
 * To digest raw HTML, we first decode it to unicode and then lightly
 * parse it into whitespaces, markup which could become XPath offsets,
 * and visible text that could be analyzed as natural language. Spans
 * can be divided into smaller contiguous spans, including sentences,
 * words, phrases, punctuation, etc.
 */
enum SpanType {
  WHITESPACE = 0, // space between natural language tokens and also possibly long whitespace strings separated parts of a document.
  MARKUP = 1, // includes HTML script, style, comments
  CONTENT = 2, // intended for natural language analysis
}

/**
 * two-tuple indicating *inclusive* start and *non-inclusive* end
 * indexes in `spans`.  So a span of length=1 is [n, n+1]
 */
typedef list<i32> SpanRange

/**
 * TaggerID is used as a key on maps in ContentItem.
 *
 * It is just a string.  There is no enum for it, so consistency and
 * uniqueness depends on the system generating the TaggerID.
 */
typedef string TaggerID

struct Tagging {
  1: TaggerID tagger_id,

  /**
   * raw output of the tagging tool
   */
  2: binary raw_tagging,

  /**
   * short human-readable description of configuration parameters
   */
  3: optional string tagger_config,

  /**
   * short human-readable version string of the tagging tool
   */
  4: optional string tagger_version,

  /**
   * time that tagging was generated
   */
  5: optional StreamTime generation_time,
}

/**
 * Desription of a selector discovered by an extractor in the text.
 */
struct Selector {
  /**
   * what type of selector this is
   */
  1: optional string selector_type

  /**
   * the selector string as it appears in the document
   */
  2: string raw_selector

  /**
   * the selector string in a canonical form
   */
  3: string canonical_selector

  /**
   * pointer to the selector string within the clean_visible document
   */
  4: optional map<OffsetType, Offset> offsets = {},

  /**
   * optional metadata binary string, such as a JSON or CBOR blob,
   * depends on the selector_type.
   */
  5: optional binary metadata
}

enum ZoneType {
  UNZONED = 0,
  HEADER = 1,
  TITLE = 2,
  BODY = 3,
  FOOTER = 4,
}

/**
 * Desription of a Zone discovered by an extractor in the text.
 */
struct Zone {
  /**
   * what type of zone this is
   */
  1: ZoneType zone_type

  /**
   * For a given OffsetType provide a *list* of Offset objects
   */
  2: map<OffsetType, list<Offset>> offsets = {},
}

/**
 * RelationType is used in Relation to map relation "name" to type.
 *
 * Relations 0 through 50 borrow from ACE with these string replacements:
 * s/-// and s/./_/
 * http://projects.ldc.upenn.edu/ace/docs/English-Events-Guidelines_v5.4.3.pdf
 *
 * Relations 51-  borrows from KBP slot filling
 * http://surdeanu.info/kbp2013/TAC_2013_KBP_Slot_Descriptions_1.0.pdf
 *
 * Most entity slots are relations, so the PER_ and ORG_ and FAC_
 * relations listed below are primary for slot filling.
 *
 * Many of the KBP-based slots are redundant or overlapping with the
 * ACE-based slots.  The KBP-based slots are generally simpler and
 * were developed to support knowledge base population rather than
 * single-document extraction (as ACE was).  Therefore, for KB-focused
 * tasks, we recommend using the Relations 51-
 */
enum RelationType {
  PHYS_Located = 0,
  PHYS_Near = 1,
  PARTWHOLE_Geographical = 2,
  PARTWHOLE_Subsidiary = 3,
  PARTWHOLE_Artifact = 4,
  PERSOC_Business = 5,
  PERSOC_Family = 6,
  PERSOC_LastingPersonal = 7,
  ORGAFF_Employment = 8,
  ORGAFF_Ownership = 9,
  ORGAFF_Founder = 10,
  ORGAFF_StudentAlum = 11,
  ORGAFF_SportsAffiliation = 12,
  ORGAFF_InvestorShareholder = 13,
  ORGAFF_Membership = 14,
  ART_UserOwnerInventorManufacturer = 15,
  GENAFF_CitizenResidentReligionEthnicity = 16,
  GENAFF_OrgLocation = 17,
  Business_DeclareBankruptcy = 18,
  Business_EndOrg = 19,
  Business_MergeOrg = 20,
  Business_StartOrg = 21,
  Conflict_Attack = 22,
  Conflict_Demonstrate = 23,
  Contact_PhoneWrite = 24,
  Contact_Meet = 25,
  Justice_Acquit = 26,
  Justice_Appeal = 27,
  Justice_ArrestJail = 28,
  Justice_ChargeIndict = 29,
  Justice_Convict = 30,
  Justice_Execute = 31,
  Justice_Extradite = 32,
  Justice_Fine = 33,
  Justice_Pardon = 34,
  Justice_ReleaseParole = 35,
  Justice_Sentence = 36,
  Justice_Sue = 37,
  Justice_TrialHearing = 38,
  Life_BeBorn = 39,
  Life_Die = 40,
  Life_Divorce = 41,
  Life_Injure = 42,
  Life_Marry = 43,
  Movement_Transport = 44,
  Personnel_Elect = 45,
  Personnel_EndPosition = 46,
  Personnel_Nominate = 47,
  Personnel_StartPosition = 48,
  Transaction_TransferMoney = 49,
  Transaction_TransferOwnership = 50,


  PER_DATE_OF_BIRTH = 51,
  PER_COUNTRY_OF_BIRTH = 52,
  PER_STATEORPROVINCE_OF_BIRTH = 53,
  PER_CITY_OF_BIRTH = 54,
  PER_ORIGIN = 55,
  PER_DATE_OF_DEATH = 56,
  PER_COUNTRY_OF_DEATH = 57,
  PER_STATEORPROVINCE_OF_DEATH = 58,
  PER_CITY_OF_DEATH = 59,
  PER_COUNTRIES_OF_RESIDENCE = 60,
  PER_STATESORPROVINCES_OF_RESIDENCE = 61,
  PER_CITIES_OF_RESIDENCE = 62,
  PER_SCHOOLS_ATTENDED = 63,
  PER_EMPLOYEE_OR_MEMBER_OF = 64,
  PER_RELIGION = 65,
  PER_SPOUSE = 66,
  PER_CHILDREN = 67,
  PER_PARENTS = 68,
  PER_SIBLINGS = 69,
  PER_OTHER_FAMILY = 70,

  ORG_TOP_MEMBERS_EMPLOYEES = 71,
  ORG_MEMBERS = 72,
  ORG_MEMBER_OF = 73,
  ORG_SUBSIDIARIES = 74,
  ORG_PARENTS = 75,
  ORG_FOUNDED_BY = 76,
  ORG_DATE_FOUNDED = 77,
  ORG_DATE_DISSOLVED = 78,
  ORG_COUNTRY_OF_HEADQUARTERS = 79,
  ORG_STATEORPROVINCE_OF_HEADQUARTERS = 80,
  ORG_CITY_OF_HEADQUARTERS = 81,
  ORG_SHAREHOLDERS = 82,
  ORG_POLITICAL_OR_RELIGIOUS_AFFILIATION = 83,
  ORG_WEBSITE = 84,

  FAC_LOCATED = 85,
  FAC_VISITED_BY = 86,
  FAC_OWNER = 87,

  PER_WON_AWARD = 88,
  PER_MET_WITH = 89, // PER or ORG
  PER_ATTENDED = 90, // meeting event
  PER_VISITED = 91,  // FAC (more general than attended)

  ORG_ATTENDED = 92, // meeting event
  ORG_VISITED = 93, // meeting event

  PER_WEBSITE = 94,
  PER_NATIONALITY = 95,
}

/**
 * Description of a relation between two entities that a tagger
 * discovered in the text.
 */
struct Relation {
  /**
   * The type of the relation, see documentation for RelationType
   *
   */
  1: optional RelationType relation_type,

  /**
   * Zero-based index into the sentences array for this TaggerID
   */
  2: optional i32 sentence_id_1,

  /**
   * Index into the mentions in the document.  This identifies the
   * origin of the relation.  For example, the relation
   *    (Bob, PHYS_Located, Chicago)
   * would have mention_id_1 point to Bob.
   */
  3: optional MentionID mention_id_1,

  /**
   * Zero-based index into the sentences array for this TaggerID
   */
  4: optional i32 sentence_id_2,

  /**
   * Index into the mentions in the document. This identifies the
   * origin of the relation.  For example, the relation
   *    (Bob, PHYS_Located, Chicago)
   * would have mention_id_2 point to Chicago.
   */
  5: optional MentionID mention_id_2,

  // could add equiv_id_1 and equiv_id_2
}

/**
 * Description of a natural language used in text
 */
struct Language {
  /**
   * two letter code for the language
   */
  1: string code,
  2: optional string name,
}

/**
 * Description of a natural language used in text
 */
struct Mention { // v4
  /**
   * A bridge structure carrying references into other structures...  TODO: explain more
   */
  1: optional Confidence confidence,
  2: optional SentenceID sentence_id,
  3: optional SpanRange span_range,
}

/**
 * A knowledge-base-like record for each entity recognized in
 * `StreamItem.body`.  This serves two purposes: it carries the list
 * of Mentions for efficiently highlighting mentions of the entity in
 * a visual display of the document, and it points to the
 * `body.contexts` that characterize the entity.
 */
struct Entity { // v4

  /**
   * Consider these possible methods of constructing identifiers for
   * entities mentioned within a document:
   *
   * - arbitrary integer selected by NER engine(s), which is not
   *   stable across software upgrades that re-analyze the text.
   *
   * - first character in the "best" mention.  Fails to be unique on
   *   mentions like "Albany First National Bank", which might occur
   *   in an article about Albany.
   *
   * - tuple of (first, length) for the best mention.  Tuples do not
   *   work as keys in a map.
   *
   * - cbor.dumps((first, length))does work as a key in a map.
   */
  1: optional CorefChainID coref_chain_id,

  /**
   * List of `Mention` objects in order of appearance in text.
   */
  2: optional list<Mention> mentions = [],

  /**
   * Index position in mentions of a representative mention, which is
   * also used to construct the coref_chain_id
   */
  3: optional i32 best_id,

  /**
   * See discussion of hierarchical entity classes.
   */
  4: optional list<EntityClassAddress> entity_classes = [],

  /**
   * A general structure for holding attribute-like information that
   * has not yet been reified to a particular ontology or schema.
   */
  5: optional list<ContextID> descriptions = [],

  /**
   * A general structure for holding entity-to-entity relation-like
   * information that has not yet been reified to a particular
   * ontology or schema.
   */
  6: optional map<CorefChainID, list<ContextID>> associations = {},

  /**
   * When an Entity is resolved, its meaning should be recorded in a
   * `Label` object.
   */
  7: optional list<Label> kb_links = [],

}


/**
 * ContentItem contains raw data, an indication of its character
 * encoding, and various transformed versions of the raw data.
 */
struct ContentItem {
  /**
   * original download, raw byte array
   */
  1: optional binary raw,

  /**
   * guessed from raw and/or headers, e.g. by python-requests.org
   */
  2: optional string encoding,

  /**
   * Content-type header from fetching the data, or MIME type
   */
  3: optional string media_type,

  /**
   * HTML-formatted version of raw with UTF8 encoding and no broken
   * tags.  All HTML-escaped characters are converted to their UTF8
   * equivalents.  < > & are escaped.
   */
  4: optional string clean_html,

  /**
   * All tags stripped from clean_html and replaced with whitespace,
   * so they have the same byte offsets.  The only escaped characters
   * are < > &, so that this can be treated as Character Data in XML:
   * http://www.w3.org/TR/xml/#syntax
   *
   * Again: must be UTF8
   */
  5: optional string clean_visible,

  /**
   * Logs generated from processing pipeline, for forensics
   */
  6: optional list<string> logs = [],

  /**
   * A set of auto-generated taggings, such as a One-Word-Per-Line
   * (OWLP) tokenization and sentence chunking with part-of-speech,
   * lemmatization, and NER classification.  The string name should be
   * the same as the tagger_id and also corresponds to the key in
   * sentences or sentence_blobs, which get generated by transforming
   * a Tagging.raw_tagging into Sentence and Token instances
   *
   * Taggings are generated from 'clean_visible' so offsets (byte,
   * char, line) refer to clean_visible and clean_html -- not raw.
   */
  7: optional map<TaggerID, Tagging> taggings = {},

  /**
   * sets of annotations
   */
  8: optional map<AnnotatorID, list<Label>> labels = {},

  /**
   * parsed Sentence objects generated by an NLP pipeline identified
   * by the string name, which is a tagger_id that connects this
   * Sentences instance to the Tagging struct from which it came
   */
  9: optional map<TaggerID, list<Sentence>> sentences = {},

  /**
   * same as 'sentences' except the array of Sentence instances are
   * serialized into a binary string that can be read by the Thrift's
   * binary protocol.  This allows lazy deserialization via an
   * iterator -- one sentence at a time.  This might be totally
   * unnecessary, because at least some of the Thrift language
   * implementations have lazy object construction, e.g. --gen
   * py:dynamic,slots
   */
  10: optional map<TaggerID, binary> sentence_blobs = {},

  /**
   * indication of which natural language is used in the text
   */
  11: optional Language language,

  /**
   * List of relations discovered in clean_visible
   */
  12: optional map<TaggerID, list<Relation>> relations = {},

  /**
   * List of attributes discovered in clean_visible
   */
  13: optional map<TaggerID, list<Attribute>> attributes = {},

  /**
   * Map of external identifier strings to mention_ids generated by a
   * particular tagger.  This allows external systems to associate
   * record IDs with individual mentions, or sets of mentions.
   */
  14: optional map<TaggerID, map<MentionID, string>> external_ids = {},

  /**
   * Map of external identifier strings to selectors in clean_visible
   */
  15: optional map<TaggerID, list<Selector>> selectors = {},

  /**
   * Map of external identifier strings to Zones.  As indicated by
   * content_form or content_cleanse_level in the Offset, it may refer
   * to clean_visible or raw_characters.
   */
  16: optional map<TaggerID, map<ZoneType, Zone>> zones = {},

  /**
   * Unicode character string represented as UTF-8 bytes from decoding
   * the binary `raw` data.
   */
  17: optional string raw_characters,

  /**
   * Ordered list of the lengths of spans in `raw_characters`
   */
  18: optional list<i32> span_lengths,

  /**
   * See description of `SpanType`
   */
  19: optional list<SpanType> span_types,

  /**
   * List of strings split at `span_lengths`
   *
   * In the interest of saving space, an implementation may omit `raw`
   * and `raw_characters` in favor of using `spans` as the primary
   * form of the content.
   *
   * An implementation may set MARKUP spans to '' and represent the
   * MARKUP in span_xpaths.
   *
   *  if not ContentItem.span_xpaths:
   *      assert u''.join(spans) == raw_characters
   *  else:
   *      assert len(spans) == len(span_xpaths)
   *
   * Since span_lengths is redundant, it could be omitted.  If
   * present, then:
   *
   *  if ContentItem.span_lengths:
   *      assert len(spans) == len(span_lengths)
   *
   * Note the lack of TaggerID.  This is a *single* primary
   * tokenization of the document that a system could construct from a
   * primary tokenizer and possibly further modify by token
   * "improvers."
   */
  20: optional list<string> spans,

  /**
   * List of integers from the HtmlTags enum representing an XPath
   * relative to the previous MARKUP span.  For example, a MARKUP span
   * of "</p></li></ol><div>" would be [0, 0, 0, 36].
   */
  21: optional list<list<i16>> span_xpaths,

  /**
   * For each position in spans, a list of other strings that a system
   * could/should index as variations to boost recall.  This is
   * pre-indexing query expansion.  For example, stemmed and
   * lemmatized strings appear here.
   *
   * assert len(normalized_spans) == len(spans)
   *
   * TODO: assess whether this should change to something simpler,
   * like a bag-of-word-variants for the whole document.
   */
  22: optional list<list<string>> normalized_spans,

  /**
   * List of begin/end ranges of spans for sentence chunking; index
   * positions into sentence_spans are called `SentenceId`
   */
  23: optional list<SpanRange> sentence_spans,

  /**
   * Index from CorefChainID --> Entity structs
   */
  24: optional map<CorefChainID, Entity> entities = {},

  /**
   * ContextId is indexes into this list
   *
   * The binary blob is a general way of carrying feature vector data,
   * such as dossier.fc.FeatureCollection or other data that is
   * constructed and defined by a particular system.
   */
  25: optional list<binary> contexts = [],

}


/**
 * Ratings are buman generated assertions about a entire document's
 * utility for a particular topic or entity in a reference KB.
 */
struct Rating {
  /**
   * identifies the source of this Rating
   */
  1: Annotator annotator,

  /**
   * identifies the information need assessed by annotator
   */
  2: Target target,

  /**
   * numerical score assigned by annotator to "judge" or "rate" the
   * utility of this StreamItem to addressing the target information
   * need.  The range and interpretation of relevance numbers depends
   * on the annotator.  relevance can represent a rank ordering or an
   * enumeration such as -1=Garbage, 0=Neutral, 1=Useful, 2=Vital
   */
  3: optional i16 relevance,

  /**
   * true|false indication of whether the document mentions the target
   * entity.  This is only partially correlated with relevance.  For
   * example, a document might mention the entity only in chrome text
   * on the side such that it is a Garbage-rated text for that entity.
   */
  4: optional bool contains_mention,

  /**
   * Save notes from Annotator about this Rating
   */
  5: optional string comments,


  /**
   * Record strings that are "mentions" of the target in this text
   */
  6: optional list<string> mentions,

  /**
   * General purpose flags. These flags can be used to mark documents
   * as meeting an extensible set of criteria.
   */
  7: optional list<FlagType> flags,
}

/**
 * SourceMetadata is a binary object with format determined by the key
 * in StreamItem.source_metadata, which is often the same as
 * StreamItem.source.
 *
 * For the kba-stream-corpus-2012, the SourceMetadata was always one
 * of these schemas where 'news', 'social', 'linking' is the string
 * found in StreamItem.source and the source_metadata map's key:
 *  - http://trec-kba.org/schemas/v1.0/news-metadata.json
 *  - http://trec-kba.org/schemas/v1.0/linking-metadata.json
 *  - http://trec-kba.org/schemas/v1.0/social-metadata.json
 *
 * Other keys in the source_metadata map can be:
 *
 *  - http_headers
 */
typedef binary SourceMetadata

/**
 * Versions of this protocol are enumerated so that when we expand,
 * everybody can see which version a particular data file used.
 *
 * v0_1_0 refers to the kba.thrift definition, which was before
 * Versions was included in the spec.
 */
enum Versions {
  v0_2_0 = 0,
  v0_3_0 = 1,
  v0_4_0 = 2,
}

/**
 * SystemID and DocIDorStreamID are used below in
 * StreamItem.external_ids, these are just to make this file more
 * self-documenting.
 */
typedef string SystemID
typedef string DocIDorStreamID

/**
 * When content is retrieved from remote servers, useful data can be
 * buried in the request-response data of HTTP Transactions.  In
 * particular, redirect chains can help identify duplicate documents,
 * and information can be embedded in the various URLs that point at a
 * document.
 *
 * For more details, see http://blog.catchpoint.com/2010/09/17/anatomyhttp/
 */
struct HttpTransaction {
  /**
   * hostname sent to DNS
   */
  1: optional string hostname,

  /**
   * IP address obtained from DNS
   */
  2: optional string ip_address,

  /**
   * byte string of HTTP Request
   */
  3: optional binary request,

  /**
   * byte string of HTTP Response headers *without* the body.
   */
  4: optional binary response,

  /**
   * Data from an HTTP *before* the final transaction.  The final
   * transaction creates the `body` property on the `StreamItem`.  It
   * is possible for an HTTP Redirect to have a non-empty body,
   * e.g. an interstitial page saying "standby". This `body` property
   * is intended to capture that data when present.
   */
  5: optional ContentItem body,
}


/**
 * This is the primary interface to the corpus data.  It is called
 * StreamItem rather than CorpusItem and has a required StreamTime
 * attribute, because even for a static corpus, each document was
 * captured at a particular time in Earth history and might have been
 * different if captured earlier or later.  All corpora are stream
 * corpora, even if they were not explicitly created as such.
 *
 * stream_id is the unique identifier for documents in the corpus.
 *
 * This is similar to the StreamItem defined in kba.thrift for TREC
 * KBA 2012, however it removes the 'title' and 'anchor' fields, which
 * can now be represented in other_content.  This means that code that
 * was written to read messages from kba.thrift must be updated.
 */
struct StreamItem {
  /**
   * must provide a version number here
   */
  1: Versions version = Versions.v0_4_0,

  /**
   * md5 hash of the abs_url
   */
  2: string doc_id,

  /**
   * normalized form of the original_url, should be a valid URL
   */
  3: optional binary abs_url,

  /**
   * scheme://hostname parsed from abs_url
   */
  4: optional string schost,

  /**
   * string obtain from some source.  Only present if not a valid URL,
   * in which case abs_url was derived from original_url
   */
  5: optional binary original_url,

  /**
   * string uniquely identifying this data set, should start with a
   * year string, such as 'news' or 'social'
   */
  6: optional string source,

  /**
   * primary content
   */
  7: optional ContentItem body,

  /**
   * see above for explanation of the values that can appear in this
   * dictionary of metadata info from the source.  The string keys in
   * this map should be short, descriptive, and free of whitespace.
   */
  8: optional map<string, SourceMetadata> source_metadata = {},

  /**
   * stream_id is actual unique identifier for a StreamItem.  The
   * format is:
   *
   * stream_id = '%d-%s' % (int(stream_time.epoch_ticks), doc_id)
   */
  9: string stream_id,

  /**
   * earliest time that this content was known to exist.  Usually,
   * body.raw was also saved at the time of that first observation.
   */
  10: StreamTime stream_time,

  /**
   * such as title, anchor, extracted, etc.  When present, 'anchor',
   * is a single anchor text of a URL pointing to this doc.  Note that
   * this does not have metadata like the URL of the page that
   * contained this anchor.  Such general link graph data may
   * eventually motivate an extension to this thrift interface.
   */
  11: optional map<string, ContentItem> other_content = {},

  /**
   * doc-level judgments relating entire StreamItem to a Target
   */
  12: optional map<AnnotatorID, list<Rating>> ratings = {},

  /**
   * doc-level map connecting either doc_id or stream_id (or both) to
   * external identifiers.  This allows external systems to associate
   * record IDs with individual doc_id or stream_id of this document.
   * The keys in the second level map can be either doc_id or
   * stream_id, or possibly other IDs in the future.
   */
  14: optional map<SystemID, map<DocIDorStreamID, string>> external_ids = {},

  /**
   * If provided, this lists the sequence of possibly multiple HTTP
   * Transactions that led to the `body` `ContentItem`.  The first
   * item in the list is the initial request-response, and the last
   * item in the list is the request-response that carried the body
   * content that became the `body` attribute on this `StreamItem`.
   * Multiple transactions result from *redirects*.  The `abs_url` is
   * the *final* URL in the redirect chain, and the `original_url` is
   * the original string that may have required cleanup before
   * initiating the first request that started the chain.
   */
  15: optional list<HttpTransaction> http_transactions = [],

}
